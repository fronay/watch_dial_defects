{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-10-f9b75e544dae>, line 39)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-10-f9b75e544dae>\"\u001b[0;36m, line \u001b[0;32m39\u001b[0m\n\u001b[0;31m    print 'x_train shape:', x_train.shape\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "'''Trains a simple convnet on the MNIST dataset.\n",
    "Gets to 99.25% test accuracy after 12 epochs\n",
    "(there is still a lot of margin for parameter tuning).\n",
    "16 seconds per epoch on a GRID K520 GPU.\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDKexdwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c3a008d50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "[[ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from skimage import io\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('my_model.h5')\n",
    "# sample = io.imread(\"Python-Custom-Digit-Recognition/goran_arnautovic.png\",as_grey=True)\n",
    "sample = io.imread(\"DICK.png\", as_grey=True)\n",
    "gimbo = sample\n",
    "#gimbo = x_train[9].squeeze()\n",
    "# print(y_train[9])\n",
    "plt.imshow(gimbo)\n",
    "plt.show()\n",
    "gimbo = np.expand_dims(gimbo, axis=0)\n",
    "gimbo = np.expand_dims(gimbo, axis=0)\n",
    "\n",
    "\n",
    "dildo = model.predict(gimbo,verbose=0)\n",
    "print(np.argmax(dildo))\n",
    "print(dildo)\n",
    "# model.predict(sample, verbose=1)\n",
    "\n",
    "# print(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
